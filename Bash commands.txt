Bash commands 
_____________
Resources: 

https://devhints.io/bash 
https://ss64.com/osx/
https://www.csvexplorer.com/blog/open-big-csv/
https://data36.com/bash-intro-2-data-coding-101/
https://macpaw.com/how-to/use-terminal-on-mac

Working with tables: 

https://www.stefaanlippens.net/pretty-csv.html
https://gist.github.com/soxofaan/af407f793382623d039805f50144af6e

0. Learn more about commands
_____________

- Hold "Esc" and press y to show all available commands 
- [man] [command_name] to learn more about this command and available options
_____________

1. Count the number of rows in a csv

wc -l file.csv
_____________

2. Print the first (or last) 100 lines of big_file.csv

head -100 file.csv
tail -100 file.csv
_____________

3. Print lines that contain the word "novosibirsk"

grep novosibirsk file.csv
_____________

4. Print lines that contain the word "novosibirsk" and write them to a new file, sample.csv

grep novosibirsk file.csv > sample.csv 
_____________

5. [iTerm 2] Builds a table, recognizing "," as a delimiter, prints output into "123.txt", prints "123.txt" in the shell and allows to scroll left and right 

column -t -s  , nsk.csv > 123.txt && cat 123.txt | less -S

___________________________________________________________________________________________
___________________________________________________________________________________________
___________________________________________________________________________________________


Checking if there is a user who has more than 1 device

Make a userbase snapshot through Admin CP and download it to your workstation. Put it into a folder, e.g. Downloads
Open the Terminal and change directory to Downloads (copy paste the commands one by one, press Enter after each command)

cd /Users/YourUserName/Downloads

Rename your dump file into something human readable, e.g. AskfmDump.010319.csv

mv FEB61-0762D_2504452f526e690d698508ced5640ac4.csv AskfmDump.010319.csv

Remove everything inside {} (tags values), because each device has unknown number of tags set which prevents us from counting columns (do not think why, just trust me ;)

sed -e 's/\({\).*\(}\)/\1\2/' AskfmDump.010319.csv > wobrackets.csv

Remove all columns before 11th to get the list of userIDs (note, your customer may have a non-standard database scheme. Look at the first few lines of the dump to check what is the number of userIDs column in your file. You can get first 10 lines of the file with the command head AskfmDump.010319.csv userID column should be ~12th, so in the command set 11)

cut -d, -f11-  wobrackets.csv > usersonly.csv

Remove all excessive commas from the file

sed 's/\,//g' usersonly.csv > wocommas.csv

Remove all empty lines from the file

sed '/^$/d' wocommas.csv > wospaces.csv

Sort the file with userIDs

sort wospaces.csv > wospacesSorted.csv 

Remove duplicate entries from the file

sort -u wospacesSorted.csv -o wospacesUnique.csv

Compare file will all userIDs and with unique userIDs to get the list of duplicates (userIDs which are listed more than once in the dump because they have >1 device)

comm -23 wospacesSorted.csv wospacesUnique.csv > Duplicates.csv

Count the number of duplicates

wc -l Duplicates.csv

If the task was completed correctly, number of duplicates must be = number of lines in wospacesSorted.csv minus number of lines in wospacesUnique.csv